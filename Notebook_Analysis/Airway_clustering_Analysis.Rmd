---
title: "Airway Disease Clustering with decesion tree and unsupervised feature transformation"
output: html_notebook
---

# instaling libraries needed
```{r loadlib, include=FALSE}
mydata <- read.csv('/Users/xbasra/Documents/Data/Airway_Clustering/Original_Data/Airway Disease Phenotyping Data Sets5/WSAS And OLIN Airway Disease Phenotyping.csv')
#library('FactoMineR')
library(tidyverse)
library(treeClust)
library(factoextra)
library(Rtsne)
library(ggplot2)
library(umap)
library(NbClust)
```

## Preprocessing the dataset for the projection methods as well as scaling the data

```{r}
Airway2 <- Get_Binary_data(mydata)

# scaling with caret average
ordinalCol_Airway <- c('ever_smoker20py', 'dyspneaMRC')
pp <- preProcess(Airway2[Airway_spilts$numeric], method = "range")
pp1 <- preProcess(Airway2[ordinalCol_Airway], method = "range")
scaled_Airway <- Airway2
scaled_Airway[Airway_spilts$numeric]<- predict(pp, Airway2[Airway_spilts$numeric])
scaled_Airway[ordinalCol_Airway] <- predict(pp1, Airway2[ordinalCol_Airway])
# saving the data
write.csv(Airway2, '/Users/xbasra/Documents/Data/Clustering/Results_Data_Reports/CsvData/Airway2.csv')
```


```{r}
# important to set a seed here
set.seed(33)
airway.tc1 <- treeClust(Airway2, d.num = 1, control = treeClust.control(return.trees = TRUE, return.dists = TRUE))
h_tree <- hcut(airway.tc1$dists, 6, isdiss = TRUE, hc_method = 'ward.D2')
table(h_tree$cluster)
```

```{r}
set.seed(10)
# Tsne for tree distacne
tsne_tree_distance <- Rtsne(X = airway.tc1$dists, is_distance = TRUE, check_duplicates = FALSE)

tsne_tree_distance <- tsne_tree_distance$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))
tsne_tree_distance$cl <- factor(h_tree$cluster)
ggplot(tsne_tree_distance, aes(x=X, y=Y, color=cl)) + geom_point()
```

# UFT

```{r}
set.seed(33)
drops_numerical <-Airway_spilts$numeric
Airway_cate <- Airway2[ , !(names(Airway2) %in% drops_numerical)]

Airway_cate_to_num <- Airway_cate
m <- length(Airway_cate_to_num)
d <- dim(Airway_cate_to_num)[1]
for (j in 1:m) {
  n <- length(unique(Airway_cate[,j])) 
  S <- as.vector(as.matrix(count(Airway_cate, Airway_cate[,j], sort = TRUE)[,1])) # the unique values of variable (we did this some that the order match with count and probabilities)
  C <- as.vector(as.matrix(count(Airway_cate, Airway_cate[,j], sort = TRUE)[,2])) # the count (number of occurance) of the values in the variable
  P <- C/(d*1) # Probabilities
  for (i in 1:n){
    mu <- 0
    L1 <- 0
    L2 <- 1- sum(P^3)
    L3 <- 0
    for (h in 1:n) {
      H <- P[h]*P[i]*(h-i)^2
      L3 <- H + L3
    }
    for (k in 1:i){
      mu1 <- sum((n-k) * P[k])
      L1 <- L1 + mu1
    }
    mu <- ((n -i) - L1) * sqrt(L2/L3)
    for (l in 1:d){
      if (Airway_cate_to_num[l,j] == S[i]){
        Airway_cate_to_num[l,j] <- rnorm(1,mu, P[i])
      }
    }
  }
}
```


```{r}
converted_airway <- bined_converted_func(converted_data = Airway_cate_to_num_only_cate, original_data = Airway2)
#write.csv(Airway_cate_to_num, '/Users/xbasra/Documents/Data/Clustering/Results_Data_Reports/CsvData/converted_UFT.csv')
```

```{r}
set.seed(50)
tsne_converted <- Rtsne(X = converted_airway ,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)

tsne_converted <- tsne_converted$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = tsne_converted)  + geom_point()
```

- umap
```{r}
set.seed(14)
converted_umap <- umap(converted_airway)

converted_umap <- converted_umap$layout %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = converted_umap)  + geom_point()
```

```{r}
Nb_converted <- NbClust(converted_airway, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted)
```


```{r}
set.seed(111)
k_converted <- kmeans(converted_airway, centers = 6, nstart = 100)
grp_k_converted <- k_converted$cluster
table(grp_k_converted)
```

```{r}
set.seed(222)
converted_umap <- umap(converted_airway)

converted_umap_df <- converted_umap$layout %>%
  data.frame() %>%
  setNames(c("X", "Y"))

converted_umap_df$cluster <- grp_k_converted
ggplot(aes(x = X, y = Y, color = as.factor(cluster)), data = converted_umap_df) +
    geom_point() + scale_color_brewer(palette="Dark2")

```



# Train_test to validate the clustering results

- we will first start with spliting the data to train and test set randomly
- we will second apply UFT method on the train data and then cluster the data using k-means.
- we will third split the train data agian to train and test parts and train a model (random forest) on that data.
- we go to the orignal test data and apply UFT method then k-means clustering.
- we use the model we trained in the previous step to predict the the labels (clusters).
- Now we can compare between the two clusters on the original test set . we use this as a validation creteria.
- we can apply the above program to all the methods we develop such as Gower, UFT, Treeclust, and maybe the Ensemble approachas well.
- we can also possibly use the rando forest crafer or the model based approaches as well as the deep learning results with bootstrap.

```{r}
library(caret)
library(e1071)
library(mclust)
library(clusterCrit)
library(randomForest)
```


## UFT train_test validation


- Spliting the data

```{r}
n_train <- round(0.80 * nrow(Airway2)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(Airway2), n_train) #creating a vector with random indices
val_train <- Airway2[train_indices, ] #generating train data set (with ideces = train_indices)
val_test <- Airway2[-train_indices, ] #generating test data set
```

- UFT Clustering for the training data
```{r}
val_train_airway_cate_to_num  <- UFT_func(val_train, Seed = 22)
val_train_converted_airway <- bined_converted_func(converted_data = val_train_airway_cate_to_num, original_data = val_train)
```

- Clustering the data using k-means

```{r}
set.seed(10)
tsne_converted_airway_val <- Rtsne(X = val_train_converted_airway,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)

tsne_converted_airway_val <- tsne_converted_airway_val$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = tsne_converted_airway_val)  + geom_point()
```

```{r}
library(NbClust)
Nb_converted_val_train <- NbClust(val_train_converted_airway, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted_val_train)
```

- Clustering with k-means

```{r}
set.seed(11)
k_converted_airway_val_train <- kmeans(val_train_converted_airway, centers = 6, nstart = 100)
grp_k_converted_val_train <- k_converted_airway_val_train$cluster
table(grp_k_converted_val_train)
```

- Adding the cluster to the data

```{r}
# copying the data
splited_train_airway_converted <- val_train_converted_airway
splited_train_airway_converted$clusters <- as.factor(grp_k_converted_val_train)
```


- second spliting of the data

```{r}
n_train <- round(0.8 * nrow(splited_train_airway_converted)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(splited_train_airway_converted), n_train) #creating a vector with random indices
split_train <- splited_train_airway_converted[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- splited_train_airway_converted[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split

```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway <- randomForest(clusters ~ ., data = split_train, importance = TRUE)
SplitRF_model_airway
```
```{r}
importance(SplitRF_model_airway, type = 1)
```

```{r}
plot(SplitRF_model_airway, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway$err.rate),
       fill = 1:ncol(SplitRF_model_airway$err.rate))
```

```{r}
varImpPlot(SplitRF_model_airway, main = "Importance of Variables") #plot variance importance
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$clusters) 
```

- going to the orignal test data and apply UFT method then k-means clustering.

```{r}
val_test_airway_cate_to_num <- UFT_func(Data = val_test, Seed = 22)
val_test_airway_converted <- bined_converted_func(converted_data = val_test_airway_cate_to_num, original_data = val_test)
```

- Clustering the data using k-means

```{r}
set.seed(10)
tsne_converted_airway_val_test <- Rtsne(X = val_test_airway_converted,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)

tsne_converted_airway_val_test <- tsne_converted_airway_val_test$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))
ggplot(aes(x = X, y = Y), data = tsne_converted_airway_val_test)  + geom_point()

tsne_converted_airway_val_test$cl <- factor(grp_k_converted_val_test)
ggplot(tsne_converted_airway_val_test, aes(x=X, y=Y, color=cl)) + geom_point()
```

```{r}
library(NbClust)
Nb_converted_val_test <- NbClust(val_test_airway_converted, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted_val_test)
```


- Clustering with k-means

```{r}
#set.seed(11)
k_converted_airway_val_test <- kmeans(val_test_airway_converted, centers = 4, nstart = 100)
grp_k_converted_val_test <- k_converted_airway_val_test$cluster
table(grp_k_converted_val_test)
```


```{r}
predValid_class_val <- predict(SplitRF_model_airway, val_test_airway_converted, type = "class")
adjustedRandIndex(predValid_class_val, grp_k_converted_val_test)

extCriteria(as.integer(predValid_class_val), grp_k_converted_val_test, crit = "all")
```

# Another validation approach 
- We run clustering on the data
- we split the data to two parts train and validation
- we split the train to two sets train and test
- we fit a model on the train data and test it on the test set
- we run the model on the validation part to predict the clusters
- we compare between the prediction and the labels



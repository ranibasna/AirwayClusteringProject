---
title: "Airway Disease Clustering with decesion tree and unsupervised feature transformation"
output: html_notebook
---

# instaling libraries needed
```{r loadlib, include=FALSE}
mydata <- read.csv('/Users/xbasra/Documents/Data/Airway_Clustering/Original_Data/Airway Disease Phenotyping Data Sets5/WSAS And OLIN Airway Disease Phenotyping.csv')
#library('FactoMineR')
library(tidyverse)
library(treeClust)
library(factoextra)
library(Rtsne)
library(ggplot2)
#library(umap)
library(NbClust)
```

```{r validation libraries, include=FALSE}
library(caret)
library(e1071)
library(mclust)
library(clusterCrit)
library(randomForest)
```

```{r}
ClusterPurity <- function(clusters, classes) {
  sum(apply(table(classes, clusters), 2, max)) / length(clusters)}
```

## Preprocessing the dataset for the projection methods as well as scaling the data

```{r}
Airway2 <- Get_Binary_data(mydata)
# converting the binary / categorical variables to factors for presentation tabels and results perpuses 
Airway2_f <- Airway2 %>% mutate_if(is.integer, factor)
# saving the data Airway2_f
write.csv(Airway2_f, '/Users/xbasra/Documents/Data/Airway_Clustering/Intermediate/Preprocessed_data/Airway2_f.csv')
write.csv(Airway2, '/Users/xbasra/Documents/Data/Airway_Clustering/Intermediate/Preprocessed_data/Airway2.csv')
```

# Decesion Tree distance and Hierarchical Clustering

```{r}
# important to set a seed here
set.seed(33)
airway.tc1 <- treeClust(Airway2, d.num = 1, control = treeClust.control(return.trees = TRUE, return.dists = TRUE))
h_tree <- hcut(airway.tc1$dists, 6, isdiss = TRUE, hc_method = 'ward.D2')
table(h_tree$cluster)
```

```{r}
# 5 clusters is what mostly reported
Nb_converted_DT <- NbClust(data = Airway2, diss = airway.tc1$dists,distance = NULL, min.nc = 4,
max.nc = 10, method = 'ward.D2')
fviz_nbclust(Nb_converted_DT)
```

```{r}
set.seed(10)
# Tsne for tree distacne
tsne_tree_distance <- Rtsne(X = airway.tc1$dists, is_distance = TRUE, check_duplicates = FALSE)

tsne_tree_distance <- tsne_tree_distance$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))
tsne_tree_distance$cl <- factor(h_tree$cluster)
ggplot(tsne_tree_distance, aes(x=X, y=Y, color=cl)) + geom_point()
```

# UFT
```{r}
Airway_cate_to_num_only_cate  <- UFT_func(Airway2, Seed = 33)
converted_airway <- bined_converted_func(converted_data = Airway_cate_to_num_only_cate, original_data = Airway2)
write.csv(converted_airway, '/Users/xbasra/Documents/Data/Airway_Clustering/Intermediate/Preprocessed_data/converted_airway.csv')
```

```{r}
set.seed(50)
tsne_converted <- Rtsne(X = converted_airway ,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)
tsne_converted <- tsne_converted$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = tsne_converted)  + geom_point()
```

- umap
```{r}
set.seed(14)
converted_umap <- umap(converted_airway)
converted_umap <- converted_umap$layout %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = converted_umap)  + geom_point()
```

```{r}
# 5 clusters is what mostly reported
Nb_converted <- NbClust(converted_airway, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted)
```


```{r}
set.seed(111)
k_converted <- kmeans(converted_airway, centers = 6, nstart = 100)
grp_k_converted <- k_converted$cluster
table(grp_k_converted)
```

```{r}
k_Clusters <- AirwaClusteringKmeans(original_raw_data = mydata)
```


```{r}
converted_umap$cluster <- grp_k_converted
ggplot(aes(x = X, y = Y, color = as.factor(cluster)), data = converted_umap) +
    geom_point() + scale_color_brewer(palette="Dark2")

```

# Deeplearning with reticulate
```{r}
# library(reticulate)
# #.libPaths()
# #use_condaenv('AirwayClust')
# use_condaenv(condaenv = 'AirwayClust', conda = "/Users/xbasra/miniconda3/envs/AirwayClust/")
# 
# import pandas
# import numpy as np

```


# Validation with Train_test to validate the clustering results

- we will first start with spliting the data to train and test set randomly
- we will second apply UFT method on the train data and then cluster the data using k-means.
- we will third split the train data agian to train and test parts and train a model (random forest) on that data.
- we go to the orignal test data and apply UFT method then k-means clustering.
- we use the model we trained in the previous step to predict the the labels (clusters).
- Now we can compare between the two clusters on the original test set . we use this as a validation creteria.
- we can apply the above program to all the methods we develop such as Gower, UFT, Treeclust, and maybe the Ensemble approachas well.
- we can also possibly use the rando forest crafer or the model based approaches as well as the deep learning results with bootstrap.




## UFT train_test validation


- Spliting the data

```{r}
n_train <- round(0.80 * nrow(Airway2)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(Airway2), n_train) #creating a vector with random indices
val_train <- Airway2[train_indices, ] #generating train data set (with ideces = train_indices)
val_test <- Airway2[-train_indices, ] #generating test data set
```

- UFT Clustering for the training data
```{r}
val_train_airway_cate_to_num  <- UFT_func(val_train, Seed = 22)
val_train_converted_airway <- bined_converted_func(converted_data = val_train_airway_cate_to_num, original_data = val_train)
```

- Clustering the data using k-means

```{r}
set.seed(10)
tsne_converted_airway_val <- Rtsne(X = val_train_converted_airway,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)

tsne_converted_airway_val <- tsne_converted_airway_val$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))

ggplot(aes(x = X, y = Y), data = tsne_converted_airway_val)  + geom_point()
```

```{r}
library(NbClust)
Nb_converted_val_train <- NbClust(val_train_converted_airway, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted_val_train)
```

- Clustering with k-means

```{r}
set.seed(11)
k_converted_airway_val_train <- kmeans(val_train_converted_airway, centers = 6, nstart = 100)
grp_k_converted_val_train <- k_converted_airway_val_train$cluster
table(grp_k_converted_val_train)
```

- Adding the cluster to the data

```{r}
# copying the data
splited_train_airway_converted <- val_train_converted_airway
splited_train_airway_converted$clusters <- as.factor(grp_k_converted_val_train)
```


- second spliting of the data

```{r}
n_train <- round(0.8 * nrow(splited_train_airway_converted)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(splited_train_airway_converted), n_train) #creating a vector with random indices
split_train <- splited_train_airway_converted[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- splited_train_airway_converted[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split
## RF-model
```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway <- randomForest(clusters ~ ., data = split_train, importance = TRUE)
SplitRF_model_airway
```
```{r}
importance(SplitRF_model_airway, type = 1)
```

```{r}
plot(SplitRF_model_airway, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway$err.rate),
       fill = 1:ncol(SplitRF_model_airway$err.rate))
```

```{r}
varImpPlot(SplitRF_model_airway, main = "Importance of Variables") #plot variance importance
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$clusters) 
```

- going to the orignal test data and apply UFT method then k-means clustering.

```{r}
val_test_airway_cate_to_num <- UFT_func(Data = val_test, Seed = 22)
val_test_airway_converted <- bined_converted_func(converted_data = val_test_airway_cate_to_num, original_data = val_test)
```

- Clustering the data using k-means

```{r}
set.seed(10)
tsne_converted_airway_val_test <- Rtsne(X = val_test_airway_converted,perplexity= 30, is_distance = FALSE, check_duplicates = FALSE)

tsne_converted_airway_val_test <- tsne_converted_airway_val_test$Y %>%
  data.frame() %>%
  setNames(c("X", "Y"))
ggplot(aes(x = X, y = Y), data = tsne_converted_airway_val_test)  + geom_point()

tsne_converted_airway_val_test$cl <- factor(grp_k_converted_val_test)
ggplot(tsne_converted_airway_val_test, aes(x=X, y=Y, color=cl)) + geom_point()
```

```{r}
Nb_converted_val_test <- NbClust(val_test_airway_converted, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(Nb_converted_val_test)
```


- Clustering with k-means

```{r}
#set.seed(11)
k_converted_airway_val_test <- kmeans(val_test_airway_converted, centers = 4, nstart = 100)
grp_k_converted_val_test <- k_converted_airway_val_test$cluster
table(grp_k_converted_val_test)
```


```{r}
predValid_class_val <- predict(SplitRF_model_airway, val_test_airway_converted, type = "class")
adjustedRandIndex(predValid_class_val, grp_k_converted_val_test)

extCriteria(as.integer(predValid_class_val), grp_k_converted_val_test, crit = "all")
```

# Another validation approach 
- We run clustering on the data
- we split the data to two parts train and validation
- we split the train to two sets train and test
- we fit a model on the train data and test it on the test set
- we run the model on the validation part to predict the clusters
- we compare between the prediction and the labels

- Adding the cluster to the big main data
## UFT

```{r}
# copying the data
converted_airway_full <- converted_airway
converted_airway_full$clusters <- as.factor(grp_k_converted)
```

```{r}
n_train <- round(0.9 * nrow(converted_airway_full)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(converted_airway_full), n_train) #creating a vector with random indices
split_train <- converted_airway_full[train_indices, ] #generating train data set (with ideces = train_indices)
split_validate <- converted_airway_full[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split

```{r}
n_train <- round(0.9 * nrow(split_train)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(split_train), n_train) #creating a vector with random indices
split_train_train <- split_train[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- split_train[-train_indices, ] #generating test data set
```

```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway <- randomForest(clusters ~ ., data = split_train_train, importance = TRUE)
SplitRF_model_airway
```

```{r}
plot(SplitRF_model_airway, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway$err.rate),
       fill = 1:ncol(SplitRF_model_airway$err.rate))
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$clusters) 
```

```{r}
predValid_class_val <- predict(SplitRF_model_airway, split_validate %>% select(- clusters), type = "class")
#adjustedRandIndex(predValid_class_val, split_validate$clusters)
extCriteria(as.integer(predValid_class_val), as.integer(split_validate$clusters), crit = "all")
```

```{r}
ClusterPurity(predValid_class_val,split_validate$cluster)
```


## Dt
```{r}
# copying the data
Airway2_full <- Airway2
Airway2_full$clusters <- as.factor(h_tree$cluster)
```

```{r}
n_train <- round(0.9 * nrow(Airway2_full)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(Airway2_full), n_train) #creating a vector with random indices
split_train <- Airway2_full[train_indices, ] #generating train data set (with ideces = train_indices)
split_validate <- Airway2_full[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split

```{r}
n_train <- round(0.9 * nrow(split_train)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(split_train), n_train) #creating a vector with random indices
split_train_train <- split_train[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- split_train[-train_indices, ] #generating test data set
```

```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway_Dt <- randomForest(clusters ~ ., data = split_train_train, importance = TRUE)
SplitRF_model_airway_Dt
```

```{r}
plot(SplitRF_model_airway_Dt, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway_Dt$err.rate),
       fill = 1:ncol(SplitRF_model_airway_Dt$err.rate))
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway_Dt, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway_Dt, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$clusters) 
```

```{r}
predValid_class_val <- predict(SplitRF_model_airway_Dt, split_validate %>% select(- clusters), type = "class")
#adjustedRandIndex(predValid_class_val, split_validate$clusters)
extCriteria(as.integer(predValid_class_val), as.integer(split_validate$clusters), crit = "all")
```

```{r}
ClusterPurity(predValid_class_val,split_validate$cluster)
```


## Deep learning DEC

```{r}
# copying the data
result_airway_uft_DEC_full <- read.csv('/Users/xbasra/Documents/Data/Airway_Clustering/Intermediate/CSV_output_data/result_airway_uft_DEC.csv')
result_airway_uft_DEC_full$cluster <- as.factor(result_airway_uft_DEC_full$cluster) 

n_train <- round(0.9 * nrow(result_airway_uft_DEC_full)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(result_airway_uft_DEC_full), n_train) #creating a vector with random indices
split_train <- result_airway_uft_DEC_full[train_indices, ] #generating train data set (with ideces = train_indices)
split_validate <- result_airway_uft_DEC_full[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split

```{r}
n_train <- round(0.9 * nrow(split_train)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(split_train), n_train) #creating a vector with random indices
split_train_train <- split_train[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- split_train[-train_indices, ] #generating test data set
```

```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway_DEC <- randomForest(cluster ~ ., data = split_train_train, importance = TRUE)
SplitRF_model_airway_DEC
```

```{r}
plot(SplitRF_model_airway_DEC, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway_DEC$err.rate),
       fill = 1:ncol(SplitRF_model_airway_DEC$err.rate))
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway_DEC, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway_DEC, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$cluster) 
```

```{r}
predValid_class_val <- predict(SplitRF_model_airway_DEC, split_validate %>% select(- cluster), type = "class")
#adjustedRandIndex(predValid_class_val, split_validate$cluster)
extCriteria(as.integer(predValid_class_val), as.integer(split_validate$cluster), crit = "all")
```
```{r}
ClusterPurity(predValid_class_val,split_validate$cluster)
```

## N2D


```{r}
# copying the data
result_airway_uft_n2d_full <- read.csv('/Users/xbasra/Documents/Data/Airway_Clustering/Intermediate/CSV_output_data/result_airway_uft_n2d.csv')
result_airway_uft_n2d_full$cluster <- as.factor(result_airway_uft_n2d_full$cluster) 

n_train <- round(0.9 * nrow(result_airway_uft_n2d_full)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(result_airway_uft_n2d_full), n_train) #creating a vector with random indices
split_train <- result_airway_uft_n2d_full[train_indices, ] #generating train data set (with ideces = train_indices)
split_validate <- result_airway_uft_n2d_full[-train_indices, ] #generating test data set
```

- Training the model on the train data of the second split

```{r}
n_train <- round(0.9 * nrow(split_train)) #80% of length of main data set as integer
train_indices <- sample(1:nrow(split_train), n_train) #creating a vector with random indices
split_train_train <- split_train[train_indices, ] #generating train data set (with ideces = train_indices)
split_train_test <- split_train[-train_indices, ] #generating test data set
```

```{r}
# Create a Random Forest model with default parameters
SplitRF_model_airway_n2d <- randomForest(cluster ~ ., data = split_train_train, importance = TRUE)
SplitRF_model_airway_n2d
```

```{r}
plot(SplitRF_model_airway_n2d, main = "Model Error by Number of Trees")
legend(x = "right", 
       legend = colnames(SplitRF_model_airway_n2d$err.rate),
       fill = 1:ncol(SplitRF_model_airway_n2d$err.rate))
```

```{r}
# Predicting on Validation set
predValid <- predict(SplitRF_model_airway_n2d, split_train_test, type = "prob")
predValid_class <- predict(SplitRF_model_airway_n2d, split_train_test, type = "class")
confusionMatrix(data = predValid_class, reference = split_train_test$cluster) 
```


```{r}
ClusterPurity(predValid_class_val,split_validate$cluster)
```


```{r}
predValid_class_val <- predict(SplitRF_model_airway_n2d, split_validate %>% select(- cluster), type = "class")
adjustedRandIndex(predValid_class_val, split_validate$cluster)
extCriteria(as.integer(predValid_class_val), as.integer(split_validate$cluster), crit = "all")
```

